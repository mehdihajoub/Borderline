{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24724,"status":"ok","timestamp":1714321790582,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"9q-GfZjNpjGc","outputId":"f3dd6948-be51-4c4b-b122-597760ebeb20"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1714321793324,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"UGFHpEdhpntw"},"outputs":[],"source":["!ln -s \"/content/drive/My Drive/Borderline/\" \"/content/\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1714321795398,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"Y0qr-yzcpp9l","outputId":"00d573d6-85c3-4048-e039-4f484db3169e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Borderline\n"]}],"source":["%cd Borderline"]},{"cell_type":"markdown","metadata":{"id":"gJLtbT-WzREN"},"source":["# Classification"]},{"cell_type":"markdown","metadata":{"id":"qPmK_2c-p9k4"},"source":["## Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9610,"status":"ok","timestamp":1714321808010,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"IeWUNhEyp9cF"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import Adam\n","from torch.utils.data import Subset, DataLoader, random_split, Dataset\n","from torch.optim import lr_scheduler\n","import torch.utils.data as data\n","from torchvision import transforms\n","from transformers import BertTokenizer, AdamW, BertForSequenceClassification\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","import numpy as np\n","import os\n","import time\n","import copy\n","import random\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"DEQ4QQ4gqFDY"},"source":["#Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1714321811305,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"hk3bg1aNp8uO"},"outputs":[],"source":["class TweetsDataset(Dataset):\n","    def __init__(self, filename, tokenizer, max_len):\n","        self.data = pd.read_csv(filename)\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.LABEL_MAP = {'hate': 1, 'nothate': 0}\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        tweet = self.data.loc[index, 'text']\n","        label = self.LABEL_MAP[self.data.loc[index, 'label']]\n","\n","        encodings = self.tokenizer(tweet, max_length=self.max_len, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        return {\n","            'input_ids': encodings['input_ids'].squeeze(),  # Use squeeze to remove batch dimension\n","            'attention_mask': encodings['attention_mask'].squeeze(),\n","            'labels': torch.tensor(label, dtype=torch.long)  # Use torch.long for labels\n","        }\n"]},{"cell_type":"markdown","metadata":{"id":"MfGm-EtVqRHN"},"source":["#Hyperparameters"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1714321814621,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"lLv8gbIsqQd1"},"outputs":[],"source":["MAX_LEN = 128\n","BATCH_SIZE = 72\n","LEARNING_RATE = 2e-5\n","NUM_EPOCHS = 10\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"qox95IEer7a8"},"source":["# Dataset init and Dataloaders"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6486,"status":"ok","timestamp":1714321823091,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"y66NoxxvqL5d","colab":{"base_uri":"https://localhost:8080/","height":267,"referenced_widgets":["9becf1e6c8264c28ae11eabd9b8dc4f9","7d46cdeee93345fb8f5f97679141a35a","da00efb1606d43dea5eabd7ea8839d5e","4721ea7b592d4f30ba45c109c6ec72db","f32edc2f0e204cb7a524cc6e948450c1","81e725133ac14f319e292204aa366655","2e9b39eaf5174e19a764e623e411c674","61e8a7b3eff6407f94588532764b215e","af13c2e5e3f04b29853ad5f3f54f61dc","e81988548d5d44fe83cea97897c82efd","5a31c775670a4cc5b9dc983786cd2358","adeab4faffb94c6ab5d346b832f8fd12","46287272713b4d75963ec71b2630082e","bcd296de8e3447798e4906c30a9e71ac","c39c8744f17443b38932971d703bac6b","fb139b4d17494308b7d4a5e8eb8da8bc","ac496162743e4e71b2ee10102e27d8ad","f0d6e1507523449abcf58fb3942cb531","75fb418e36a2470e914c2369fad83a43","04b60d8758594525a3c71934ab18c134","fd1f1b105fcb4bd1b356a03ca2c15b37","b5ae41ed0bcc4d4db7766b0bf058c88f","f852cdaabacc4ea18a26af8b97d51e0e","04ae7e524e4849aab34e605c4d08be69","035605a502b540da9673caba009d2ec4","8bff3240474c4070bcc4ed5548d508d7","68b0b40a01cc4641838ff3047f4d53ce","317a62c226c04702b4011ed54311b070","5e58c6ecd35545698cbeea1737927911","79159947af4c4c1c8ffeb643f0acff32","9b835a2df8804fe8969a4bf0842bf80c","b32757851d4c47b198f899aa13d9216f","455108439a204b5ca066f14c005b96eb","59b0fbda46b945179063319e2f375822","96b61acd934d4a578459f03ebed3e82e","2b45274f82df42f9be45789990ba0136","064eccaff77b470c8eddd96ab8ab97a8","f66e86bceec74a339f9e6607d4c8b5ea","73a9af4a40cf413a8490d3007355d73c","5e282157683948279b4bfe3bfc181808","15f1e402040b40389f3208472a016b64","c99944b4247c44ba98606efc4db7d18a","362d8dab81174555972a5bf0abc7d598","dd10a53c5f444e82a453f2548451d9aa"]},"outputId":"8f0d1516-6454-421a-fc9f-b655d3635f23"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9becf1e6c8264c28ae11eabd9b8dc4f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adeab4faffb94c6ab5d346b832f8fd12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f852cdaabacc4ea18a26af8b97d51e0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59b0fbda46b945179063319e2f375822"}},"metadata":{}}],"source":["csv_path = 'data/data.csv'\n","tokenizer = tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","dataset = TweetsDataset(csv_path, tokenizer, MAX_LEN)\n","\n","dataset_size = int(len(dataset)/8)\n","dataset_indices = list(range(dataset_size))\n","train_indices, temp_indices = train_test_split(dataset_indices, test_size=0.2, random_state=42)\n","val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n","\n","\n","train_subset = Subset(dataset, train_indices)\n","val_subset = Subset(dataset, val_indices)\n","test_subset = Subset(dataset, test_indices)\n","\n","train_loader = DataLoader(train_subset, BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_subset, BATCH_SIZE, shuffle=False)\n","test_loader = DataLoader(test_subset, BATCH_SIZE, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"IzTNC9uFsICi"},"source":["#Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":681,"status":"ok","timestamp":1714295675964,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"m5ArsiOwsHcQ","outputId":"751f456c-decd-4fee-a3d6-b35d0ecf0766"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":13}],"source":["classifier = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","classifier.to(DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"h8Fdilj8sZXG"},"source":["# Optimizier and Learning Rate Scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":251,"status":"ok","timestamp":1714295678675,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"VqBQpBehscPI","outputId":"ca58aafa-f48d-4713-c27e-d37f3e56bd92"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["optimizer = AdamW(classifier.parameters(), lr=LEARNING_RATE)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JX7wZ-KfsdSU"},"outputs":[],"source":["classifier.train()\n","\n","for epoch in range(NUM_EPOCHS):\n","    epoch_loss = 0\n","    for idx, batch in enumerate(train_loader):\n","        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n","        outputs = classifier(**batch)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        scheduler.step()\n","        epoch_loss += loss.item()\n","\n","    epoch_loss = epoch_loss/dataset_size\n","    print(f'Epoch {epoch}', 'Epoch loss :', epoch_loss )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2304,"status":"ok","timestamp":1713972858795,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"OFE6EIeovbQt","outputId":"9d067236-44b0-4feb-b5b2-296bfa966ab8"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.78      0.81      0.79       242\n","           1       0.82      0.79      0.81       272\n","\n","    accuracy                           0.80       514\n","   macro avg       0.80      0.80      0.80       514\n","weighted avg       0.80      0.80      0.80       514\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","classifier.eval()\n","predictions, true_labels = [], []\n","with torch.no_grad():\n","    for batch in val_loader:\n","        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n","        outputs = classifier(**batch)\n","        logits = outputs.logits\n","        preds = torch.argmax(logits, dim=1)\n","        predictions.extend(preds.cpu().numpy())\n","        true_labels.extend(batch['labels'].cpu().numpy())\n","\n","print(classification_report(true_labels, predictions))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZy4Kqv-wNik"},"outputs":[],"source":["torch.save(classifier.state_dict(), 'classifier.pth')"]},{"cell_type":"markdown","metadata":{"id":"tyRkHSotz2-L"},"source":["# Opposite Generator"]},{"cell_type":"code","source":["import json\n","\n","def convert_and_save_json(input_filename, output_filename):\n","    # Load the original JSON data from the file\n","    with open(input_filename, 'r') as file:\n","        original_data = json.load(file)\n","\n","    # Transform the data into a list of dictionaries with 'Sentence' and 'Opposite' keys\n","    transformed_data = [{'Sentence': k, 'Opposite': v} for k, v in original_data.items()]\n","\n","    # Save the transformed data to a new JSON file\n","    with open(output_filename, 'w') as outfile:\n","        json.dump(transformed_data, outfile, indent=4)\n","\n","# Specify the input and output file names\n","input_filename = '/content/Borderline/data/dataset.json'\n","output_filename = '/content/Borderline/data/transformed_dataset.json'\n","\n","# Run the conversion function\n","convert_and_save_json(input_filename, output_filename)\n","\n","print(f\"Data has been successfully converted and saved to {output_filename}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DLOEZuMfl_n9","executionInfo":{"status":"ok","timestamp":1714322812760,"user_tz":-120,"elapsed":438,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"}},"outputId":"4ac717d3-0c2e-46db-eb8d-fe76af807c2a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Data has been successfully converted and saved to /content/Borderline/data/transformed_dataset.json\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"MTQg1VLG8oy3","executionInfo":{"status":"ok","timestamp":1714321827750,"user_tz":-120,"elapsed":750,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n","from torch.optim.lr_scheduler import StepLR\n","import pandas as pd"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"1c0_WgdPwS12","executionInfo":{"status":"ok","timestamp":1714322978098,"user_tz":-120,"elapsed":448,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"}}},"outputs":[],"source":["class PhraseDataset(Dataset):\n","    def __init__(self, filename, tokenizer, max_len):\n","        # Load data from a JSON file. It's directly usable since the format matches DataFrame expectations\n","        self.data = pd.read_json(filename)\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        phrase = self.data.loc[index, 'Sentence']\n","        target = self.data.loc[index, 'Opposite']\n","\n","        # Tokenize the phrase and its opposite using the provided tokenizer\n","        source_encoding = self.tokenizer(phrase, max_length=self.max_len, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        target_encoding = self.tokenizer(target, max_length=self.max_len, padding='max_length', truncation=True, return_tensors=\"pt\")\n","\n","        return {\n","            'input_ids': source_encoding['input_ids'].squeeze(),  # Remove the batch dimension\n","            'attention_mask': source_encoding['attention_mask'].squeeze(),\n","            'labels': target_encoding['input_ids'].squeeze()\n","        }\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1149,"status":"ok","timestamp":1714322981910,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"D9Wa_U7u8zfL","outputId":"1ec0d9d3-8e7f-424d-bfb0-a2872339af9a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","dataset_path = '/content/Borderline/data/transformed_dataset.json'\n","oppo_dataset = PhraseDataset(dataset_path, tokenizer, max_len=512)\n","train_loader = DataLoader(oppo_dataset, batch_size=2, shuffle=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"5qPSimXr_Te8","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["24c8c7bb479c476897575bd72777ca47","71852ac9983e4bb981d5fe40874a8cc4","30501c4cb07440a0a52259f5b68e2a0b","c259dd5e400440139febb558df72c602","0a4fecc0f41948c99e4849db0e1334dd","a037cd3d0a454c6693ab8db9fe1dcb0a","61919d4af93d418c8e95db48c2e21505","06dca4d3741e46b29301017e191bcac8","87a5ac69d1194da79f4fa582dce365f3","72a3f8ee9fff4bc58bffa2376391b807","eb6212046803435babddb59dccbdd703","65f94b0fb5f7478eafb10ba14a3d8197","ddaf77ab376a424caedbb71b1eb8b797","0ebd844fe27c43a8b9818e0066c558e4","d3c53b73b2a8400c84b4dca2423a4c76","f8effce9164741f3be6ed9b99ffe12ed","10d52cbb9ef243b8a9ec64e3da6a9924","4683043c2bd84186a57b237eb3bc4b4a","bc58abb372e24577800de18c25e43047","40d75efe6d864308b65c470d7e6e0b0e","6e66fd31cbe34fdcb39133998f3c9ec8","6d4ac403500c4332a9e8d6b941680413"]},"executionInfo":{"status":"ok","timestamp":1714322994641,"user_tz":-120,"elapsed":10288,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"}},"outputId":"b7183dec-a8ff-45e4-e9aa-ca42768b77d8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24c8c7bb479c476897575bd72777ca47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65f94b0fb5f7478eafb10ba14a3d8197"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":20}],"source":["opposite_maker = T5ForConditionalGeneration.from_pretrained('t5-base')\n","opposite_maker.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":450,"status":"ok","timestamp":1714323214715,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"Mt-uZ5T6A9ZB","outputId":"94abfbb7-5953-443d-c35e-0c057a126fa6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["optimizer = AdamW(opposite_maker.parameters(), lr=1e-4)\n","scheduler = StepLR(optimizer, step_size=1000, gamma=0.95)"]},{"cell_type":"code","source":["len(train_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CX-Bk_vToFYf","executionInfo":{"status":"ok","timestamp":1714323227559,"user_tz":-120,"elapsed":18,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"}},"outputId":"809f4dc8-cbe2-4e84-c6be-25e825497a52"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["229"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":545080,"status":"ok","timestamp":1714323950691,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"NBdDZQ65B39o","outputId":"b3e234e3-3e0d-4db1-9746-08f21aadea19"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss: 22.639623641967773\n","Epoch: 0, Loss: 20.804317474365234\n","Epoch: 0, Loss: 19.313417434692383\n","Epoch: 0, Loss: 16.17634391784668\n","Epoch: 0, Loss: 15.057358741760254\n","Epoch: 0, Loss: 14.785515785217285\n","Epoch: 0, Loss: 13.262310981750488\n","Epoch: 0, Loss: 12.998199462890625\n","Epoch: 0, Loss: 10.261573791503906\n","Epoch: 0, Loss: 13.279834747314453\n","Epoch: 0, Loss: 11.648869514465332\n","Epoch: 0, Loss: 8.512600898742676\n","Epoch: 0, Loss: 9.447626113891602\n","Epoch: 0, Loss: 8.993467330932617\n","Epoch: 0, Loss: 7.436216831207275\n","Epoch: 0, Loss: 7.776683807373047\n","Epoch: 0, Loss: 6.737668037414551\n","Epoch: 0, Loss: 8.097447395324707\n","Epoch: 0, Loss: 6.072287082672119\n","Epoch: 0, Loss: 6.433104038238525\n","Epoch: 0, Loss: 4.63501501083374\n","Epoch: 0, Loss: 5.075361728668213\n","Epoch: 0, Loss: 5.452223777770996\n","Epoch: 0, Loss: 5.049422264099121\n","Epoch: 0, Loss: 3.7162294387817383\n","Epoch: 0, Loss: 3.645092725753784\n","Epoch: 0, Loss: 2.668123483657837\n","Epoch: 0, Loss: 3.298931360244751\n","Epoch: 0, Loss: 1.9298179149627686\n","Epoch: 0, Loss: 1.8584840297698975\n","Epoch: 0, Loss: 1.2104510068893433\n","Epoch: 0, Loss: 0.8506395220756531\n","Epoch: 0, Loss: 1.8041125535964966\n","Epoch: 0, Loss: 1.3998057842254639\n","Epoch: 0, Loss: 1.1344643831253052\n","Epoch: 0, Loss: 1.3378294706344604\n","Epoch: 0, Loss: 2.6647956371307373\n","Epoch: 0, Loss: 1.7731049060821533\n","Epoch: 0, Loss: 1.1248663663864136\n","Epoch: 0, Loss: 0.7817568778991699\n","Epoch: 0, Loss: 0.7536056041717529\n","Epoch: 0, Loss: 1.3712035417556763\n","Epoch: 0, Loss: 0.8952963352203369\n","Epoch: 0, Loss: 0.4513353407382965\n","Epoch: 0, Loss: 1.2852914333343506\n","Epoch: 0, Loss: 0.7476039528846741\n","Epoch: 0, Loss: 1.6738897562026978\n","Epoch: 0, Loss: 0.4906392991542816\n","Epoch: 0, Loss: 0.5458206534385681\n","Epoch: 0, Loss: 0.5393766760826111\n","Epoch: 0, Loss: 0.4420980215072632\n","Epoch: 0, Loss: 0.3008381426334381\n","Epoch: 0, Loss: 0.3551308214664459\n","Epoch: 0, Loss: 0.3502640724182129\n","Epoch: 0, Loss: 0.3198872208595276\n","Epoch: 0, Loss: 0.37961557507514954\n","Epoch: 0, Loss: 0.4537616968154907\n","Epoch: 0, Loss: 0.27602770924568176\n","Epoch: 0, Loss: 0.33792391419410706\n","Epoch: 0, Loss: 0.2707992494106293\n","Epoch: 0, Loss: 0.30598822236061096\n","Epoch: 0, Loss: 0.324628084897995\n","Epoch: 0, Loss: 0.21617212891578674\n","Epoch: 0, Loss: 0.2638188302516937\n","Epoch: 0, Loss: 0.28551676869392395\n","Epoch: 0, Loss: 0.3524101972579956\n","Epoch: 0, Loss: 0.2280828058719635\n","Epoch: 0, Loss: 0.24863150715827942\n","Epoch: 0, Loss: 0.2588200569152832\n","Epoch: 0, Loss: 0.1802944540977478\n","Epoch: 0, Loss: 0.18980368971824646\n","Epoch: 0, Loss: 0.27073636651039124\n","Epoch: 0, Loss: 0.19566486775875092\n","Epoch: 0, Loss: 0.22084800899028778\n","Epoch: 0, Loss: 0.26802489161491394\n","Epoch: 0, Loss: 0.2865907549858093\n","Epoch: 0, Loss: 0.21639856696128845\n","Epoch: 0, Loss: 0.37102723121643066\n","Epoch: 0, Loss: 0.2141144573688507\n","Epoch: 0, Loss: 0.17326396703720093\n","Epoch: 0, Loss: 0.3555254638195038\n","Epoch: 0, Loss: 0.5315340757369995\n","Epoch: 0, Loss: 0.18847917020320892\n","Epoch: 0, Loss: 0.17397309839725494\n","Epoch: 0, Loss: 0.2161371111869812\n","Epoch: 0, Loss: 0.25955337285995483\n","Epoch: 0, Loss: 0.1809445023536682\n","Epoch: 0, Loss: 0.20315612852573395\n","Epoch: 0, Loss: 0.3046576678752899\n","Epoch: 0, Loss: 0.17047543823719025\n","Epoch: 0, Loss: 0.19677942991256714\n","Epoch: 0, Loss: 0.30126115679740906\n","Epoch: 0, Loss: 0.4526527225971222\n","Epoch: 0, Loss: 0.2127213031053543\n","Epoch: 0, Loss: 0.14231841266155243\n","Epoch: 0, Loss: 0.15577605366706848\n","Epoch: 0, Loss: 0.1368602216243744\n","Epoch: 0, Loss: 0.27638936042785645\n","Epoch: 0, Loss: 0.21310685575008392\n","Epoch: 0, Loss: 0.1441579908132553\n","Epoch: 0, Loss: 0.12307674437761307\n","Epoch: 0, Loss: 0.1230231374502182\n","Epoch: 0, Loss: 0.15741151571273804\n","Epoch: 0, Loss: 0.15900197625160217\n","Epoch: 0, Loss: 0.2335396111011505\n","Epoch: 0, Loss: 0.18927735090255737\n","Epoch: 0, Loss: 0.14063234627246857\n","Epoch: 0, Loss: 0.1633898764848709\n","Epoch: 0, Loss: 0.16823405027389526\n","Epoch: 0, Loss: 0.12926821410655975\n","Epoch: 0, Loss: 0.1347130686044693\n","Epoch: 0, Loss: 0.25436916947364807\n","Epoch: 0, Loss: 0.114139124751091\n","Epoch: 0, Loss: 0.13724389672279358\n","Epoch: 0, Loss: 0.12058024853467941\n","Epoch: 0, Loss: 0.1683264523744583\n","Epoch: 0, Loss: 0.171345055103302\n","Epoch: 0, Loss: 0.133749857544899\n","Epoch: 0, Loss: 0.26651066541671753\n","Epoch: 0, Loss: 0.1286894530057907\n","Epoch: 0, Loss: 0.1256793588399887\n","Epoch: 0, Loss: 0.5861181020736694\n","Epoch: 0, Loss: 0.27208027243614197\n","Epoch: 0, Loss: 0.1254357099533081\n","Epoch: 0, Loss: 0.1392943114042282\n","Epoch: 0, Loss: 0.1064961701631546\n","Epoch: 0, Loss: 0.13619042932987213\n","Epoch: 0, Loss: 0.11143475025892258\n","Epoch: 0, Loss: 0.15331873297691345\n","Epoch: 0, Loss: 0.12767572700977325\n","Epoch: 0, Loss: 0.10527972877025604\n","Epoch: 0, Loss: 0.14372152090072632\n","Epoch: 0, Loss: 0.13716763257980347\n","Epoch: 0, Loss: 0.13747566938400269\n","Epoch: 0, Loss: 0.1307724416255951\n","Epoch: 0, Loss: 0.10513143986463547\n","Epoch: 0, Loss: 0.11636073142290115\n","Epoch: 0, Loss: 0.16208764910697937\n","Epoch: 0, Loss: 0.0949263796210289\n","Epoch: 0, Loss: 0.14402756094932556\n","Epoch: 0, Loss: 0.11818058043718338\n","Epoch: 0, Loss: 0.21303066611289978\n","Epoch: 0, Loss: 0.10838987678289413\n","Epoch: 0, Loss: 0.11379887163639069\n","Epoch: 0, Loss: 0.1079307496547699\n","Epoch: 0, Loss: 0.13667547702789307\n","Epoch: 0, Loss: 0.13377153873443604\n","Epoch: 0, Loss: 0.11550896614789963\n","Epoch: 0, Loss: 0.16980426013469696\n","Epoch: 0, Loss: 0.09593112766742706\n","Epoch: 0, Loss: 0.1392837017774582\n","Epoch: 0, Loss: 0.14322055876255035\n","Epoch: 0, Loss: 0.09686801582574844\n","Epoch: 0, Loss: 0.1280064880847931\n","Epoch: 0, Loss: 0.17365071177482605\n","Epoch: 0, Loss: 0.10827528685331345\n","Epoch: 0, Loss: 0.12056412547826767\n","Epoch: 0, Loss: 0.13059310615062714\n","Epoch: 0, Loss: 0.11290152370929718\n","Epoch: 0, Loss: 0.09967270493507385\n","Epoch: 0, Loss: 0.11405860632658005\n","Epoch: 0, Loss: 0.11872471123933792\n","Epoch: 0, Loss: 0.09960437566041946\n","Epoch: 0, Loss: 0.12453725934028625\n","Epoch: 0, Loss: 0.1188213899731636\n","Epoch: 0, Loss: 0.08702599257230759\n","Epoch: 0, Loss: 0.11874932795763016\n","Epoch: 0, Loss: 0.12080596387386322\n","Epoch: 0, Loss: 0.11554086208343506\n","Epoch: 0, Loss: 0.10544398427009583\n","Epoch: 0, Loss: 0.11585669219493866\n","Epoch: 0, Loss: 0.10628140717744827\n","Epoch: 0, Loss: 0.126333087682724\n","Epoch: 0, Loss: 0.09657551348209381\n","Epoch: 0, Loss: 0.11309310793876648\n","Epoch: 0, Loss: 0.10549543052911758\n","Epoch: 0, Loss: 0.097211554646492\n","Epoch: 0, Loss: 0.10949011892080307\n","Epoch: 0, Loss: 0.11144191026687622\n","Epoch: 0, Loss: 0.16346475481987\n","Epoch: 0, Loss: 0.100077323615551\n","Epoch: 0, Loss: 0.11468636244535446\n","Epoch: 0, Loss: 0.1163773164153099\n","Epoch: 0, Loss: 0.10676893591880798\n","Epoch: 0, Loss: 0.09454823285341263\n","Epoch: 0, Loss: 0.0904918983578682\n","Epoch: 0, Loss: 0.10004144161939621\n","Epoch: 0, Loss: 0.10305297374725342\n","Epoch: 0, Loss: 0.11333562433719635\n","Epoch: 0, Loss: 0.11271503567695618\n","Epoch: 0, Loss: 0.09723582863807678\n","Epoch: 0, Loss: 0.08442867547273636\n","Epoch: 0, Loss: 0.10731135308742523\n","Epoch: 0, Loss: 0.1089310497045517\n","Epoch: 0, Loss: 0.11990511417388916\n","Epoch: 0, Loss: 0.09483173489570618\n","Epoch: 0, Loss: 0.08022984117269516\n","Epoch: 0, Loss: 0.08920684456825256\n","Epoch: 0, Loss: 0.1163536086678505\n","Epoch: 0, Loss: 0.1305055320262909\n","Epoch: 0, Loss: 0.0905417650938034\n","Epoch: 0, Loss: 0.10800518840551376\n","Epoch: 0, Loss: 0.07877501845359802\n","Epoch: 0, Loss: 0.09503184258937836\n","Epoch: 0, Loss: 0.1245419904589653\n","Epoch: 0, Loss: 0.1999981850385666\n","Epoch: 0, Loss: 0.10544680058956146\n","Epoch: 0, Loss: 0.09983278065919876\n","Epoch: 0, Loss: 0.10765757411718369\n","Epoch: 0, Loss: 0.21889369189739227\n","Epoch: 0, Loss: 0.08789411187171936\n","Epoch: 0, Loss: 0.07874014228582382\n","Epoch: 0, Loss: 0.10017483681440353\n","Epoch: 0, Loss: 0.09482230246067047\n","Epoch: 0, Loss: 0.10190057009458542\n","Epoch: 0, Loss: 0.09598441421985626\n","Epoch: 0, Loss: 0.10309106111526489\n","Epoch: 0, Loss: 0.12326522171497345\n","Epoch: 0, Loss: 0.08470862358808517\n","Epoch: 0, Loss: 0.0946345329284668\n","Epoch: 0, Loss: 0.0801534429192543\n","Epoch: 0, Loss: 0.12345565110445023\n","Epoch: 0, Loss: 0.10416225343942642\n","Epoch: 0, Loss: 0.06884537637233734\n","Epoch: 0, Loss: 0.1081295982003212\n","Epoch: 0, Loss: 0.09180254489183426\n","Epoch: 0, Loss: 0.09985176473855972\n","Epoch: 0, Loss: 0.09456968307495117\n","Epoch: 0, Loss: 0.10806111991405487\n","Epoch: 1, Loss: 0.09384341537952423\n","Epoch: 1, Loss: 0.08869465440511703\n","Epoch: 1, Loss: 0.0740605890750885\n","Epoch: 1, Loss: 0.09257889539003372\n","Epoch: 1, Loss: 0.07722552865743637\n","Epoch: 1, Loss: 0.08896210044622421\n","Epoch: 1, Loss: 0.06862058490514755\n","Epoch: 1, Loss: 0.08275729417800903\n","Epoch: 1, Loss: 0.06431625783443451\n","Epoch: 1, Loss: 0.0707230195403099\n","Epoch: 1, Loss: 0.09288172423839569\n","Epoch: 1, Loss: 0.08023302257061005\n","Epoch: 1, Loss: 0.08501497656106949\n","Epoch: 1, Loss: 0.08222071826457977\n","Epoch: 1, Loss: 0.08750935643911362\n","Epoch: 1, Loss: 0.09277737140655518\n","Epoch: 1, Loss: 0.0748385488986969\n","Epoch: 1, Loss: 0.08669041842222214\n","Epoch: 1, Loss: 0.09226774424314499\n","Epoch: 1, Loss: 0.10997909307479858\n","Epoch: 1, Loss: 0.0680529922246933\n","Epoch: 1, Loss: 0.09199979156255722\n","Epoch: 1, Loss: 0.09767772257328033\n","Epoch: 1, Loss: 0.11429467797279358\n","Epoch: 1, Loss: 0.08582250028848648\n","Epoch: 1, Loss: 0.10715670883655548\n","Epoch: 1, Loss: 0.18512967228889465\n","Epoch: 1, Loss: 0.10398151725530624\n","Epoch: 1, Loss: 0.0923759862780571\n","Epoch: 1, Loss: 0.0835740715265274\n","Epoch: 1, Loss: 0.08110132068395615\n","Epoch: 1, Loss: 0.07705966383218765\n","Epoch: 1, Loss: 0.09706414490938187\n","Epoch: 1, Loss: 0.08569910377264023\n","Epoch: 1, Loss: 0.09047064185142517\n","Epoch: 1, Loss: 0.08592954277992249\n","Epoch: 1, Loss: 0.060522161424160004\n","Epoch: 1, Loss: 0.16574880480766296\n","Epoch: 1, Loss: 0.11184851080179214\n","Epoch: 1, Loss: 0.07415633648633957\n","Epoch: 1, Loss: 0.09650907665491104\n","Epoch: 1, Loss: 0.09676173329353333\n","Epoch: 1, Loss: 0.1005917489528656\n","Epoch: 1, Loss: 0.09172003716230392\n","Epoch: 1, Loss: 0.09858303517103195\n","Epoch: 1, Loss: 0.10360087454319\n","Epoch: 1, Loss: 0.09151880443096161\n","Epoch: 1, Loss: 0.07321573048830032\n","Epoch: 1, Loss: 0.06559251993894577\n","Epoch: 1, Loss: 0.09227020293474197\n","Epoch: 1, Loss: 0.06385306268930435\n","Epoch: 1, Loss: 0.10050588101148605\n","Epoch: 1, Loss: 0.07099595665931702\n","Epoch: 1, Loss: 0.10717064887285233\n","Epoch: 1, Loss: 0.09937712550163269\n","Epoch: 1, Loss: 0.07777483761310577\n","Epoch: 1, Loss: 0.07302990555763245\n","Epoch: 1, Loss: 0.10555461049079895\n","Epoch: 1, Loss: 0.08695211261510849\n","Epoch: 1, Loss: 0.07505173236131668\n","Epoch: 1, Loss: 0.09176438301801682\n","Epoch: 1, Loss: 0.10608083754777908\n","Epoch: 1, Loss: 0.09053405374288559\n","Epoch: 1, Loss: 0.07769432663917542\n","Epoch: 1, Loss: 0.09721387177705765\n","Epoch: 1, Loss: 0.09854939579963684\n","Epoch: 1, Loss: 0.08000483363866806\n","Epoch: 1, Loss: 0.08811511099338531\n","Epoch: 1, Loss: 0.0875297412276268\n","Epoch: 1, Loss: 0.07984114438295364\n","Epoch: 1, Loss: 0.06093399226665497\n","Epoch: 1, Loss: 0.06255946308374405\n","Epoch: 1, Loss: 0.07838623225688934\n","Epoch: 1, Loss: 0.08081897348165512\n","Epoch: 1, Loss: 0.07869408279657364\n","Epoch: 1, Loss: 0.08338581770658493\n","Epoch: 1, Loss: 0.08184997737407684\n","Epoch: 1, Loss: 0.06393806636333466\n","Epoch: 1, Loss: 0.07894221693277359\n","Epoch: 1, Loss: 0.07525806128978729\n","Epoch: 1, Loss: 0.08118259906768799\n","Epoch: 1, Loss: 0.08287230134010315\n","Epoch: 1, Loss: 0.0741589218378067\n","Epoch: 1, Loss: 0.0792926549911499\n","Epoch: 1, Loss: 0.06877266615629196\n","Epoch: 1, Loss: 0.08808716386556625\n","Epoch: 1, Loss: 0.0819070041179657\n","Epoch: 1, Loss: 0.05799490213394165\n","Epoch: 1, Loss: 0.04879327118396759\n","Epoch: 1, Loss: 0.06944750994443893\n","Epoch: 1, Loss: 0.07444491237401962\n","Epoch: 1, Loss: 0.08854921907186508\n","Epoch: 1, Loss: 0.09723541885614395\n","Epoch: 1, Loss: 0.08795663714408875\n","Epoch: 1, Loss: 0.08328378200531006\n","Epoch: 1, Loss: 0.06633453071117401\n","Epoch: 1, Loss: 0.0722990483045578\n","Epoch: 1, Loss: 0.13437166810035706\n","Epoch: 1, Loss: 0.09580707550048828\n","Epoch: 1, Loss: 0.07849196344614029\n","Epoch: 1, Loss: 0.08767261356115341\n","Epoch: 1, Loss: 0.08171674609184265\n","Epoch: 1, Loss: 0.0714602991938591\n","Epoch: 1, Loss: 0.08163342624902725\n","Epoch: 1, Loss: 0.06904961168766022\n","Epoch: 1, Loss: 0.05811428651213646\n","Epoch: 1, Loss: 0.06914452463388443\n","Epoch: 1, Loss: 0.07472388446331024\n","Epoch: 1, Loss: 0.08875750005245209\n","Epoch: 1, Loss: 0.07785055041313171\n","Epoch: 1, Loss: 0.08092725276947021\n","Epoch: 1, Loss: 0.09273451566696167\n","Epoch: 1, Loss: 0.06921814382076263\n","Epoch: 1, Loss: 0.08656836301088333\n","Epoch: 1, Loss: 0.09397599846124649\n","Epoch: 1, Loss: 0.10734555870294571\n","Epoch: 1, Loss: 0.08077513426542282\n","Epoch: 1, Loss: 0.08139491826295853\n","Epoch: 1, Loss: 0.07808501273393631\n","Epoch: 1, Loss: 0.08150845766067505\n","Epoch: 1, Loss: 0.06735114008188248\n","Epoch: 1, Loss: 0.08475195616483688\n","Epoch: 1, Loss: 0.08717714250087738\n","Epoch: 1, Loss: 0.06293127685785294\n","Epoch: 1, Loss: 0.0845053493976593\n","Epoch: 1, Loss: 0.07526814937591553\n","Epoch: 1, Loss: 0.07071441411972046\n","Epoch: 1, Loss: 0.08440866321325302\n","Epoch: 1, Loss: 0.07688730210065842\n","Epoch: 1, Loss: 0.0790739506483078\n","Epoch: 1, Loss: 0.06337665766477585\n","Epoch: 1, Loss: 0.0932726114988327\n","Epoch: 1, Loss: 0.08184373378753662\n","Epoch: 1, Loss: 0.08275526762008667\n","Epoch: 1, Loss: 0.07371873408555984\n","Epoch: 1, Loss: 0.07063937932252884\n","Epoch: 1, Loss: 0.08431592583656311\n","Epoch: 1, Loss: 0.09029502421617508\n","Epoch: 1, Loss: 0.07149967551231384\n","Epoch: 1, Loss: 0.07003689557313919\n","Epoch: 1, Loss: 0.0609528087079525\n","Epoch: 1, Loss: 0.08157575875520706\n","Epoch: 1, Loss: 0.07189907133579254\n","Epoch: 1, Loss: 0.06241297721862793\n","Epoch: 1, Loss: 0.07679754495620728\n","Epoch: 1, Loss: 0.07225388288497925\n","Epoch: 1, Loss: 0.08012795448303223\n","Epoch: 1, Loss: 0.09492294490337372\n","Epoch: 1, Loss: 0.08266174048185349\n","Epoch: 1, Loss: 0.08723302185535431\n","Epoch: 1, Loss: 0.06539446115493774\n","Epoch: 1, Loss: 0.08813343197107315\n","Epoch: 1, Loss: 0.075681172311306\n","Epoch: 1, Loss: 0.08170577883720398\n","Epoch: 1, Loss: 0.07914697378873825\n","Epoch: 1, Loss: 0.06515274941921234\n","Epoch: 1, Loss: 0.08030904084444046\n","Epoch: 1, Loss: 0.07141678035259247\n","Epoch: 1, Loss: 0.08885986357927322\n","Epoch: 1, Loss: 0.0964900553226471\n","Epoch: 1, Loss: 0.045614276081323624\n","Epoch: 1, Loss: 0.08262693881988525\n","Epoch: 1, Loss: 0.06676787883043289\n","Epoch: 1, Loss: 0.05840939283370972\n","Epoch: 1, Loss: 0.06351171433925629\n","Epoch: 1, Loss: 0.08193666487932205\n","Epoch: 1, Loss: 0.08418402820825577\n","Epoch: 1, Loss: 0.049729812890291214\n","Epoch: 1, Loss: 0.07685550302267075\n","Epoch: 1, Loss: 0.061073098331689835\n","Epoch: 1, Loss: 0.04767909646034241\n","Epoch: 1, Loss: 0.07021064311265945\n","Epoch: 1, Loss: 0.054736800491809845\n","Epoch: 1, Loss: 0.07325004041194916\n","Epoch: 1, Loss: 0.040840014815330505\n","Epoch: 1, Loss: 0.07059291750192642\n","Epoch: 1, Loss: 0.07496244460344315\n","Epoch: 1, Loss: 0.0805484727025032\n","Epoch: 1, Loss: 0.07883788645267487\n","Epoch: 1, Loss: 0.0599912665784359\n","Epoch: 1, Loss: 0.06027066335082054\n","Epoch: 1, Loss: 0.06590855121612549\n","Epoch: 1, Loss: 0.050795622169971466\n","Epoch: 1, Loss: 0.060601040720939636\n","Epoch: 1, Loss: 0.074313223361969\n","Epoch: 1, Loss: 0.06881769746541977\n","Epoch: 1, Loss: 0.06194984167814255\n","Epoch: 1, Loss: 0.08144228160381317\n","Epoch: 1, Loss: 0.07549318671226501\n","Epoch: 1, Loss: 0.08151406049728394\n","Epoch: 1, Loss: 0.07504376769065857\n","Epoch: 1, Loss: 0.04213755577802658\n","Epoch: 1, Loss: 0.06434749811887741\n","Epoch: 1, Loss: 0.06875631213188171\n","Epoch: 1, Loss: 0.06322776526212692\n","Epoch: 1, Loss: 0.0943228080868721\n","Epoch: 1, Loss: 0.06582160294055939\n","Epoch: 1, Loss: 0.0868505984544754\n","Epoch: 1, Loss: 0.06421854346990585\n","Epoch: 1, Loss: 0.06036801636219025\n","Epoch: 1, Loss: 0.05454292520880699\n","Epoch: 1, Loss: 0.05504200607538223\n","Epoch: 1, Loss: 0.07480488717556\n","Epoch: 1, Loss: 0.07167956978082657\n","Epoch: 1, Loss: 0.0705101266503334\n","Epoch: 1, Loss: 0.05731070786714554\n","Epoch: 1, Loss: 0.055056411772966385\n","Epoch: 1, Loss: 0.09064923226833344\n","Epoch: 1, Loss: 0.05310491845011711\n","Epoch: 1, Loss: 0.06726113706827164\n","Epoch: 1, Loss: 0.05833315849304199\n","Epoch: 1, Loss: 0.07229017466306686\n","Epoch: 1, Loss: 0.04551663249731064\n","Epoch: 1, Loss: 0.05788269639015198\n","Epoch: 1, Loss: 0.07679042220115662\n","Epoch: 1, Loss: 0.051538337022066116\n","Epoch: 1, Loss: 0.04474690929055214\n","Epoch: 1, Loss: 0.08439396321773529\n","Epoch: 1, Loss: 0.08414626121520996\n","Epoch: 1, Loss: 0.06563754379749298\n","Epoch: 1, Loss: 0.07643316686153412\n","Epoch: 1, Loss: 0.0548611618578434\n","Epoch: 1, Loss: 0.05154060572385788\n","Epoch: 1, Loss: 0.06614884734153748\n","Epoch: 1, Loss: 0.07634168863296509\n","Epoch: 1, Loss: 0.06607136130332947\n","Epoch: 1, Loss: 0.06286703050136566\n","Epoch: 1, Loss: 0.05623980611562729\n","Epoch: 1, Loss: 0.0729086622595787\n","Epoch: 2, Loss: 0.06305021792650223\n","Epoch: 2, Loss: 0.19176159799098969\n","Epoch: 2, Loss: 0.08359567821025848\n","Epoch: 2, Loss: 0.05908101797103882\n","Epoch: 2, Loss: 0.06078124791383743\n","Epoch: 2, Loss: 0.06750349700450897\n","Epoch: 2, Loss: 0.06555818021297455\n","Epoch: 2, Loss: 0.06301570683717728\n","Epoch: 2, Loss: 0.06538699567317963\n","Epoch: 2, Loss: 0.08214166760444641\n","Epoch: 2, Loss: 0.05720820650458336\n","Epoch: 2, Loss: 0.070330910384655\n","Epoch: 2, Loss: 0.04708587005734444\n","Epoch: 2, Loss: 0.07019875198602676\n","Epoch: 2, Loss: 0.06779936701059341\n","Epoch: 2, Loss: 0.05918522924184799\n","Epoch: 2, Loss: 0.06497659534215927\n","Epoch: 2, Loss: 0.052455440163612366\n","Epoch: 2, Loss: 0.058789148926734924\n","Epoch: 2, Loss: 0.053194984793663025\n","Epoch: 2, Loss: 0.08090584725141525\n","Epoch: 2, Loss: 0.05896742269396782\n","Epoch: 2, Loss: 0.058585312217473984\n","Epoch: 2, Loss: 0.04705055430531502\n","Epoch: 2, Loss: 0.0674930214881897\n","Epoch: 2, Loss: 0.06607121229171753\n","Epoch: 2, Loss: 0.07146937400102615\n","Epoch: 2, Loss: 0.05997949466109276\n","Epoch: 2, Loss: 0.0690610259771347\n","Epoch: 2, Loss: 0.06568367779254913\n","Epoch: 2, Loss: 0.06628784537315369\n","Epoch: 2, Loss: 0.06773903965950012\n","Epoch: 2, Loss: 0.05736926943063736\n","Epoch: 2, Loss: 0.06914077699184418\n","Epoch: 2, Loss: 0.13083083927631378\n","Epoch: 2, Loss: 0.05493608117103577\n","Epoch: 2, Loss: 0.05930414795875549\n","Epoch: 2, Loss: 0.068396657705307\n","Epoch: 2, Loss: 0.07644703984260559\n","Epoch: 2, Loss: 0.053943242877721786\n","Epoch: 2, Loss: 0.07474494725465775\n","Epoch: 2, Loss: 0.08767087757587433\n","Epoch: 2, Loss: 0.05970746651291847\n","Epoch: 2, Loss: 0.08253563940525055\n","Epoch: 2, Loss: 0.05453306436538696\n","Epoch: 2, Loss: 0.05455493554472923\n","Epoch: 2, Loss: 0.06008271127939224\n","Epoch: 2, Loss: 0.07261905819177628\n","Epoch: 2, Loss: 0.058627739548683167\n","Epoch: 2, Loss: 0.06140776351094246\n","Epoch: 2, Loss: 0.06869220733642578\n","Epoch: 2, Loss: 0.07284247130155563\n","Epoch: 2, Loss: 0.060743432492017746\n","Epoch: 2, Loss: 0.0628562867641449\n","Epoch: 2, Loss: 0.047221589833498\n","Epoch: 2, Loss: 0.057344309985637665\n","Epoch: 2, Loss: 0.06110886484384537\n","Epoch: 2, Loss: 0.05782966688275337\n","Epoch: 2, Loss: 0.055668819695711136\n","Epoch: 2, Loss: 0.06474267691373825\n","Epoch: 2, Loss: 0.06004742532968521\n","Epoch: 2, Loss: 0.061627838760614395\n","Epoch: 2, Loss: 0.07294202595949173\n","Epoch: 2, Loss: 0.05936168134212494\n","Epoch: 2, Loss: 0.06679625809192657\n","Epoch: 2, Loss: 0.052243251353502274\n","Epoch: 2, Loss: 0.0701594278216362\n","Epoch: 2, Loss: 0.06271489709615707\n","Epoch: 2, Loss: 0.05193712189793587\n","Epoch: 2, Loss: 0.05638939142227173\n","Epoch: 2, Loss: 0.05217156559228897\n","Epoch: 2, Loss: 0.05744068697094917\n","Epoch: 2, Loss: 0.03639032691717148\n","Epoch: 2, Loss: 0.05398665368556976\n","Epoch: 2, Loss: 0.06663655489683151\n","Epoch: 2, Loss: 0.06153184175491333\n","Epoch: 2, Loss: 0.06340806931257248\n","Epoch: 2, Loss: 0.049470916390419006\n","Epoch: 2, Loss: 0.07184363901615143\n","Epoch: 2, Loss: 0.05473939701914787\n","Epoch: 2, Loss: 0.06517104059457779\n","Epoch: 2, Loss: 0.04801314324140549\n","Epoch: 2, Loss: 0.0473046600818634\n","Epoch: 2, Loss: 0.055737435817718506\n","Epoch: 2, Loss: 0.05750652775168419\n","Epoch: 2, Loss: 0.057792771607637405\n","Epoch: 2, Loss: 0.15053929388523102\n","Epoch: 2, Loss: 0.041905369609594345\n","Epoch: 2, Loss: 0.0750337466597557\n","Epoch: 2, Loss: 0.03763778507709503\n","Epoch: 2, Loss: 0.06091546639800072\n","Epoch: 2, Loss: 0.07657225430011749\n","Epoch: 2, Loss: 0.06629429012537003\n","Epoch: 2, Loss: 0.06227690726518631\n","Epoch: 2, Loss: 0.0626630187034607\n","Epoch: 2, Loss: 0.06258095800876617\n","Epoch: 2, Loss: 0.07167553901672363\n","Epoch: 2, Loss: 0.06849364936351776\n","Epoch: 2, Loss: 0.06990449130535126\n","Epoch: 2, Loss: 0.056231673806905746\n","Epoch: 2, Loss: 0.05640746280550957\n","Epoch: 2, Loss: 0.04704727232456207\n","Epoch: 2, Loss: 0.07556898146867752\n","Epoch: 2, Loss: 0.0533505342900753\n","Epoch: 2, Loss: 0.05857899785041809\n","Epoch: 2, Loss: 0.05215734243392944\n","Epoch: 2, Loss: 0.06352154165506363\n","Epoch: 2, Loss: 0.056999657303094864\n","Epoch: 2, Loss: 0.20569628477096558\n","Epoch: 2, Loss: 0.04653845354914665\n","Epoch: 2, Loss: 0.05900593847036362\n","Epoch: 2, Loss: 0.0821959376335144\n","Epoch: 2, Loss: 0.0614340603351593\n","Epoch: 2, Loss: 0.06740797311067581\n","Epoch: 2, Loss: 0.06448842585086823\n","Epoch: 2, Loss: 0.04730629175901413\n","Epoch: 2, Loss: 0.04907486215233803\n","Epoch: 2, Loss: 0.058428119868040085\n","Epoch: 2, Loss: 0.08157562464475632\n","Epoch: 2, Loss: 0.047633882611989975\n","Epoch: 2, Loss: 0.061598870903253555\n","Epoch: 2, Loss: 0.054889071732759476\n","Epoch: 2, Loss: 0.047023847699165344\n","Epoch: 2, Loss: 0.05065417289733887\n","Epoch: 2, Loss: 0.0552309975028038\n","Epoch: 2, Loss: 0.06991162151098251\n","Epoch: 2, Loss: 0.0368189737200737\n","Epoch: 2, Loss: 0.06665755063295364\n","Epoch: 2, Loss: 0.06397131085395813\n","Epoch: 2, Loss: 0.060013122856616974\n","Epoch: 2, Loss: 0.06047873571515083\n","Epoch: 2, Loss: 0.06493677943944931\n","Epoch: 2, Loss: 0.06180594861507416\n","Epoch: 2, Loss: 0.0662994533777237\n","Epoch: 2, Loss: 0.058273252099752426\n","Epoch: 2, Loss: 0.05676886811852455\n","Epoch: 2, Loss: 0.0677121952176094\n","Epoch: 2, Loss: 0.060505129396915436\n","Epoch: 2, Loss: 0.049541961401700974\n","Epoch: 2, Loss: 0.06987611949443817\n","Epoch: 2, Loss: 0.08245434612035751\n","Epoch: 2, Loss: 0.06086539477109909\n","Epoch: 2, Loss: 0.06557448208332062\n","Epoch: 2, Loss: 0.07324223965406418\n","Epoch: 2, Loss: 0.07841257750988007\n","Epoch: 2, Loss: 0.05526372417807579\n","Epoch: 2, Loss: 0.04701046273112297\n","Epoch: 2, Loss: 0.04585539922118187\n","Epoch: 2, Loss: 0.05713663250207901\n","Epoch: 2, Loss: 0.05449801683425903\n","Epoch: 2, Loss: 0.0648110955953598\n","Epoch: 2, Loss: 0.04548254609107971\n","Epoch: 2, Loss: 0.07262153178453445\n","Epoch: 2, Loss: 0.07133575528860092\n","Epoch: 2, Loss: 0.05621380731463432\n","Epoch: 2, Loss: 0.04516003653407097\n","Epoch: 2, Loss: 0.0498676523566246\n","Epoch: 2, Loss: 0.05356802046298981\n","Epoch: 2, Loss: 0.036163702607154846\n","Epoch: 2, Loss: 0.035117533057928085\n","Epoch: 2, Loss: 0.06367693096399307\n","Epoch: 2, Loss: 0.05929398164153099\n","Epoch: 2, Loss: 0.06240199878811836\n","Epoch: 2, Loss: 0.06425730139017105\n","Epoch: 2, Loss: 0.051493410021066666\n","Epoch: 2, Loss: 0.058620963245630264\n","Epoch: 2, Loss: 0.05032150819897652\n","Epoch: 2, Loss: 0.03210611268877983\n","Epoch: 2, Loss: 0.06721703708171844\n","Epoch: 2, Loss: 0.07298993319272995\n","Epoch: 2, Loss: 0.042298574000597\n","Epoch: 2, Loss: 0.05844501405954361\n","Epoch: 2, Loss: 0.06610837578773499\n","Epoch: 2, Loss: 0.05090036243200302\n","Epoch: 2, Loss: 0.0632341057062149\n","Epoch: 2, Loss: 0.03387444093823433\n","Epoch: 2, Loss: 0.06175033748149872\n","Epoch: 2, Loss: 0.0578179769217968\n","Epoch: 2, Loss: 0.06892071664333344\n","Epoch: 2, Loss: 0.0378972664475441\n","Epoch: 2, Loss: 0.06179289519786835\n","Epoch: 2, Loss: 0.05077429488301277\n","Epoch: 2, Loss: 0.06031816825270653\n","Epoch: 2, Loss: 0.06968186050653458\n","Epoch: 2, Loss: 0.05073009431362152\n","Epoch: 2, Loss: 0.04393956810235977\n","Epoch: 2, Loss: 0.06027523800730705\n","Epoch: 2, Loss: 0.05175328627228737\n","Epoch: 2, Loss: 0.058009013533592224\n","Epoch: 2, Loss: 0.052399832755327225\n","Epoch: 2, Loss: 0.04276378080248833\n","Epoch: 2, Loss: 0.05492542311549187\n","Epoch: 2, Loss: 0.06837674230337143\n","Epoch: 2, Loss: 0.06090804934501648\n","Epoch: 2, Loss: 0.06794776767492294\n","Epoch: 2, Loss: 0.07069416344165802\n","Epoch: 2, Loss: 0.057083047926425934\n","Epoch: 2, Loss: 0.03782443329691887\n","Epoch: 2, Loss: 0.06124146655201912\n","Epoch: 2, Loss: 0.059307925403118134\n","Epoch: 2, Loss: 0.05423840880393982\n","Epoch: 2, Loss: 0.06146584823727608\n","Epoch: 2, Loss: 0.049908384680747986\n","Epoch: 2, Loss: 0.047092922031879425\n","Epoch: 2, Loss: 0.050212565809488297\n","Epoch: 2, Loss: 0.0627017393708229\n","Epoch: 2, Loss: 0.06271405518054962\n","Epoch: 2, Loss: 0.04846906661987305\n","Epoch: 2, Loss: 0.04025416448712349\n","Epoch: 2, Loss: 0.05643588304519653\n","Epoch: 2, Loss: 0.08853404968976974\n","Epoch: 2, Loss: 0.04904833436012268\n","Epoch: 2, Loss: 0.04525265097618103\n","Epoch: 2, Loss: 0.045856211334466934\n","Epoch: 2, Loss: 0.0461626797914505\n","Epoch: 2, Loss: 0.06340527534484863\n","Epoch: 2, Loss: 0.05853582173585892\n","Epoch: 2, Loss: 0.04127102345228195\n","Epoch: 2, Loss: 0.03932156413793564\n","Epoch: 2, Loss: 0.05926818028092384\n","Epoch: 2, Loss: 0.05553869903087616\n","Epoch: 2, Loss: 0.06302718073129654\n","Epoch: 2, Loss: 0.042052000761032104\n","Epoch: 2, Loss: 0.041848067194223404\n","Epoch: 2, Loss: 0.05077534168958664\n","Epoch: 2, Loss: 0.05542808026075363\n","Epoch: 2, Loss: 0.04150697588920593\n","Epoch: 2, Loss: 0.04760689660906792\n","Epoch: 2, Loss: 0.06555745005607605\n","Epoch: 3, Loss: 0.056466296315193176\n","Epoch: 3, Loss: 0.04088285565376282\n","Epoch: 3, Loss: 0.04129984229803085\n","Epoch: 3, Loss: 0.07381855696439743\n","Epoch: 3, Loss: 0.04809032380580902\n","Epoch: 3, Loss: 0.06679852306842804\n","Epoch: 3, Loss: 0.05883561447262764\n","Epoch: 3, Loss: 0.04654157534241676\n","Epoch: 3, Loss: 0.05593031272292137\n","Epoch: 3, Loss: 0.05339603126049042\n","Epoch: 3, Loss: 0.052850816398859024\n","Epoch: 3, Loss: 0.05291585251688957\n","Epoch: 3, Loss: 0.052861060947179794\n","Epoch: 3, Loss: 0.03542342036962509\n","Epoch: 3, Loss: 0.04427730292081833\n","Epoch: 3, Loss: 0.057174939662218094\n","Epoch: 3, Loss: 0.06484030187129974\n","Epoch: 3, Loss: 0.03633059561252594\n","Epoch: 3, Loss: 0.05634600296616554\n","Epoch: 3, Loss: 0.05719399452209473\n","Epoch: 3, Loss: 0.055216822773218155\n","Epoch: 3, Loss: 0.06058626249432564\n","Epoch: 3, Loss: 0.06030323728919029\n","Epoch: 3, Loss: 0.04739438742399216\n","Epoch: 3, Loss: 0.04754353314638138\n","Epoch: 3, Loss: 0.04120310768485069\n","Epoch: 3, Loss: 0.04468788579106331\n","Epoch: 3, Loss: 0.06505638360977173\n","Epoch: 3, Loss: 0.062239062041044235\n","Epoch: 3, Loss: 0.045443952083587646\n","Epoch: 3, Loss: 0.04661436378955841\n","Epoch: 3, Loss: 0.043212033808231354\n","Epoch: 3, Loss: 0.0521208755671978\n","Epoch: 3, Loss: 0.04454249143600464\n","Epoch: 3, Loss: 0.06717664748430252\n","Epoch: 3, Loss: 0.047120705246925354\n","Epoch: 3, Loss: 0.04854724556207657\n","Epoch: 3, Loss: 0.06035829707980156\n","Epoch: 3, Loss: 0.06750374287366867\n","Epoch: 3, Loss: 0.0536905974149704\n","Epoch: 3, Loss: 0.03503479063510895\n","Epoch: 3, Loss: 0.04091424122452736\n","Epoch: 3, Loss: 0.05784570425748825\n","Epoch: 3, Loss: 0.04583015665411949\n","Epoch: 3, Loss: 0.05628560855984688\n","Epoch: 3, Loss: 0.04785822331905365\n","Epoch: 3, Loss: 0.058317627757787704\n","Epoch: 3, Loss: 0.04314679279923439\n","Epoch: 3, Loss: 0.054359305649995804\n","Epoch: 3, Loss: 0.1538688838481903\n","Epoch: 3, Loss: 0.05102788656949997\n","Epoch: 3, Loss: 0.04642247408628464\n","Epoch: 3, Loss: 0.05885714665055275\n","Epoch: 3, Loss: 0.041805632412433624\n","Epoch: 3, Loss: 0.05197814479470253\n","Epoch: 3, Loss: 0.06459743529558182\n","Epoch: 3, Loss: 0.05215064808726311\n","Epoch: 3, Loss: 0.056265462189912796\n","Epoch: 3, Loss: 0.049373824149370193\n","Epoch: 3, Loss: 0.05099925771355629\n","Epoch: 3, Loss: 0.05507029965519905\n","Epoch: 3, Loss: 0.041857823729515076\n","Epoch: 3, Loss: 0.056544288992881775\n","Epoch: 3, Loss: 0.04523051157593727\n","Epoch: 3, Loss: 0.05672831833362579\n","Epoch: 3, Loss: 0.05342881754040718\n","Epoch: 3, Loss: 0.04723581299185753\n","Epoch: 3, Loss: 0.06019504368305206\n","Epoch: 3, Loss: 0.045175060629844666\n","Epoch: 3, Loss: 0.04836109280586243\n","Epoch: 3, Loss: 0.05697222426533699\n","Epoch: 3, Loss: 0.03460879623889923\n","Epoch: 3, Loss: 0.04641453176736832\n","Epoch: 3, Loss: 0.05628105625510216\n","Epoch: 3, Loss: 0.03546453267335892\n","Epoch: 3, Loss: 0.04435130953788757\n","Epoch: 3, Loss: 0.045683421194553375\n","Epoch: 3, Loss: 0.05369589477777481\n","Epoch: 3, Loss: 0.04231127351522446\n","Epoch: 3, Loss: 0.05150903761386871\n","Epoch: 3, Loss: 0.06268534809350967\n","Epoch: 3, Loss: 0.042378272861242294\n","Epoch: 3, Loss: 0.05113331601023674\n","Epoch: 3, Loss: 0.04381166025996208\n","Epoch: 3, Loss: 0.047789108008146286\n","Epoch: 3, Loss: 0.038406603038311005\n","Epoch: 3, Loss: 0.0563122034072876\n","Epoch: 3, Loss: 0.05098884552717209\n","Epoch: 3, Loss: 0.04340142384171486\n","Epoch: 3, Loss: 0.04470720887184143\n","Epoch: 3, Loss: 0.04580255225300789\n","Epoch: 3, Loss: 0.054890118539333344\n","Epoch: 3, Loss: 0.045690327882766724\n","Epoch: 3, Loss: 0.05471668764948845\n","Epoch: 3, Loss: 0.049421705305576324\n","Epoch: 3, Loss: 0.027011174708604813\n","Epoch: 3, Loss: 0.034217435866594315\n","Epoch: 3, Loss: 0.057014379650354385\n","Epoch: 3, Loss: 0.029335612431168556\n","Epoch: 3, Loss: 0.05594101548194885\n","Epoch: 3, Loss: 0.03985248878598213\n","Epoch: 3, Loss: 0.03682186082005501\n","Epoch: 3, Loss: 0.04987611249089241\n","Epoch: 3, Loss: 0.05491219460964203\n","Epoch: 3, Loss: 0.05929143726825714\n","Epoch: 3, Loss: 0.057584602385759354\n","Epoch: 3, Loss: 0.06298413127660751\n","Epoch: 3, Loss: 0.05252265930175781\n","Epoch: 3, Loss: 0.045875925570726395\n","Epoch: 3, Loss: 0.05665240436792374\n","Epoch: 3, Loss: 0.048854902386665344\n","Epoch: 3, Loss: 0.0467836819589138\n","Epoch: 3, Loss: 0.05749138444662094\n","Epoch: 3, Loss: 0.04537961632013321\n","Epoch: 3, Loss: 0.028607837855815887\n","Epoch: 3, Loss: 0.04937402531504631\n","Epoch: 3, Loss: 0.05533282831311226\n","Epoch: 3, Loss: 0.05458157882094383\n","Epoch: 3, Loss: 0.038349688053131104\n","Epoch: 3, Loss: 0.06097431480884552\n","Epoch: 3, Loss: 0.038369275629520416\n","Epoch: 3, Loss: 0.03890101984143257\n","Epoch: 3, Loss: 0.04359940439462662\n","Epoch: 3, Loss: 0.0564313642680645\n","Epoch: 3, Loss: 0.048176925629377365\n","Epoch: 3, Loss: 0.04878417029976845\n","Epoch: 3, Loss: 0.049209676682949066\n","Epoch: 3, Loss: 0.07130666822195053\n","Epoch: 3, Loss: 0.04179218411445618\n","Epoch: 3, Loss: 0.05006178468465805\n","Epoch: 3, Loss: 0.06211364269256592\n","Epoch: 3, Loss: 0.05189388617873192\n","Epoch: 3, Loss: 0.05268252640962601\n","Epoch: 3, Loss: 0.047317612916231155\n","Epoch: 3, Loss: 0.040017906576395035\n","Epoch: 3, Loss: 0.04509371891617775\n","Epoch: 3, Loss: 0.05185883492231369\n","Epoch: 3, Loss: 0.05222202464938164\n","Epoch: 3, Loss: 0.04435069113969803\n","Epoch: 3, Loss: 0.05292101204395294\n","Epoch: 3, Loss: 0.040044769644737244\n","Epoch: 3, Loss: 0.037714626640081406\n","Epoch: 3, Loss: 0.042421646416187286\n","Epoch: 3, Loss: 0.03474185988306999\n","Epoch: 3, Loss: 0.07497473806142807\n","Epoch: 3, Loss: 0.051683343946933746\n","Epoch: 3, Loss: 0.04460202902555466\n","Epoch: 3, Loss: 0.04263203218579292\n","Epoch: 3, Loss: 0.053998157382011414\n","Epoch: 3, Loss: 0.0580780953168869\n","Epoch: 3, Loss: 0.04701673984527588\n","Epoch: 3, Loss: 0.052305955439805984\n","Epoch: 3, Loss: 0.04056278616189957\n","Epoch: 3, Loss: 0.050447091460227966\n","Epoch: 3, Loss: 0.04392062500119209\n","Epoch: 3, Loss: 0.05734597146511078\n","Epoch: 3, Loss: 0.051138121634721756\n","Epoch: 3, Loss: 0.06692522764205933\n","Epoch: 3, Loss: 0.05991297960281372\n","Epoch: 3, Loss: 0.05089858919382095\n","Epoch: 3, Loss: 0.04026157036423683\n","Epoch: 3, Loss: 0.05323387309908867\n","Epoch: 3, Loss: 0.03788216412067413\n","Epoch: 3, Loss: 0.043981242924928665\n","Epoch: 3, Loss: 0.046465229243040085\n","Epoch: 3, Loss: 0.06446433812379837\n","Epoch: 3, Loss: 0.04561545327305794\n","Epoch: 3, Loss: 0.049531493335962296\n","Epoch: 3, Loss: 0.027815675362944603\n","Epoch: 3, Loss: 0.043903153389692307\n","Epoch: 3, Loss: 0.04522918537259102\n","Epoch: 3, Loss: 0.04503469169139862\n","Epoch: 3, Loss: 0.03576352447271347\n","Epoch: 3, Loss: 0.04689521715044975\n","Epoch: 3, Loss: 0.04588080570101738\n","Epoch: 3, Loss: 0.04689309000968933\n","Epoch: 3, Loss: 0.060022879391908646\n","Epoch: 3, Loss: 0.02931409887969494\n","Epoch: 3, Loss: 0.049525532871484756\n","Epoch: 3, Loss: 0.04063583165407181\n","Epoch: 3, Loss: 0.039710357785224915\n","Epoch: 3, Loss: 0.04549337178468704\n","Epoch: 3, Loss: 0.03489719331264496\n","Epoch: 3, Loss: 0.04992065578699112\n","Epoch: 3, Loss: 0.053531378507614136\n","Epoch: 3, Loss: 0.03831068426370621\n","Epoch: 3, Loss: 0.03954622149467468\n","Epoch: 3, Loss: 0.04709344357252121\n","Epoch: 3, Loss: 0.039460085332393646\n","Epoch: 3, Loss: 0.033898379653692245\n","Epoch: 3, Loss: 0.042975399643182755\n","Epoch: 3, Loss: 0.06141973286867142\n","Epoch: 3, Loss: 0.02782329171895981\n","Epoch: 3, Loss: 0.045609358698129654\n","Epoch: 3, Loss: 0.057654716074466705\n","Epoch: 3, Loss: 0.04720055311918259\n","Epoch: 3, Loss: 0.049682166427373886\n","Epoch: 3, Loss: 0.020723553374409676\n","Epoch: 3, Loss: 0.062031153589487076\n","Epoch: 3, Loss: 0.033249631524086\n","Epoch: 3, Loss: 0.03791792690753937\n","Epoch: 3, Loss: 0.0409272275865078\n","Epoch: 3, Loss: 0.046793509274721146\n","Epoch: 3, Loss: 0.044379521161317825\n","Epoch: 3, Loss: 0.0366135835647583\n","Epoch: 3, Loss: 0.042925819754600525\n","Epoch: 3, Loss: 0.053156040608882904\n","Epoch: 3, Loss: 0.10078126937150955\n","Epoch: 3, Loss: 0.047873202711343765\n","Epoch: 3, Loss: 0.056165728718042374\n","Epoch: 3, Loss: 0.05276576802134514\n","Epoch: 3, Loss: 0.051012229174375534\n","Epoch: 3, Loss: 0.052380435168743134\n","Epoch: 3, Loss: 0.03869083523750305\n","Epoch: 3, Loss: 0.05503110587596893\n","Epoch: 3, Loss: 0.05036080628633499\n","Epoch: 3, Loss: 0.04722890630364418\n","Epoch: 3, Loss: 0.03978549316525459\n","Epoch: 3, Loss: 0.04471374675631523\n","Epoch: 3, Loss: 0.03447423130273819\n","Epoch: 3, Loss: 0.0536499097943306\n","Epoch: 3, Loss: 0.05044715106487274\n","Epoch: 3, Loss: 0.0467686727643013\n","Epoch: 3, Loss: 0.03627181053161621\n","Epoch: 3, Loss: 0.02913638763129711\n","Epoch: 3, Loss: 0.05123717337846756\n","Epoch: 3, Loss: 0.03349120914936066\n","Epoch: 3, Loss: 0.0598299503326416\n","Epoch: 3, Loss: 0.050467103719711304\n"]}],"source":["opposite_maker.train()\n","for epoch in range(4):  # number of epochs\n","    for batch in train_loader:\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(opposite_maker.device)\n","        attention_mask = batch['attention_mask'].to(opposite_maker.device)\n","        labels = batch['labels'].to(opposite_maker.device)\n","        outputs = opposite_maker(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"WfZW3vH-ETL6","executionInfo":{"status":"ok","timestamp":1714323962268,"user_tz":-120,"elapsed":3575,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"}}},"outputs":[],"source":["torch.save(opposite_maker.state_dict(), 'opposite_maker.pth')"]},{"cell_type":"markdown","metadata":{"id":"DIYuVoCkFHXW"},"source":["## Test Opposite Maker"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"sw7jHbZyFfom","executionInfo":{"status":"ok","timestamp":1714323966417,"user_tz":-120,"elapsed":441,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"}}},"outputs":[],"source":["DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6921,"status":"ok","timestamp":1714323977353,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"},"user_tz":-120},"id":"iqV3_x0uH_jf","outputId":"8252f467-1568-436e-afcb-b714e196084f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":26}],"source":["# Initialize the tokenizer\n","tokenizer = T5Tokenizer.from_pretrained('t5-base')\n","\n","# Initialize the model with the same configuration it was trained with\n","model = T5ForConditionalGeneration.from_pretrained('t5-base')\n","model.load_state_dict(torch.load('opposite_maker.pth', map_location=DEVICE))\n","model.to(DEVICE)\n","model.eval()"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"UNqCP3oAFJ5U","executionInfo":{"status":"ok","timestamp":1714324018831,"user_tz":-120,"elapsed":417,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"}}},"outputs":[],"source":["def get_opposite_phrase(model, tokenizer, phrase, max_length=512):\n","    try:\n","        # Encode the input phrase to tensor of IDs\n","        input_ids = tokenizer.encode(phrase, return_tensors=\"pt\", max_length=max_length, truncation=True).to(DEVICE)\n","\n","\n","        # Generate output IDs from the model\n","        outputs = model.generate(input_ids, max_length=max_length)\n","\n","\n","        # Decode the generated IDs back to a string\n","        opposite_phrase = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return opposite_phrase\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","        return \"\""]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":605},"id":"nA0HBe9yFjtb","outputId":"68ad5bab-a04f-48f8-a2dc-d03c802baac9","executionInfo":{"status":"error","timestamp":1714324271311,"user_tz":-120,"elapsed":248021,"user":{"displayName":"Mehdi Hajoub","userId":"10367422732796270715"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Type 'quit' to exit.\n","Enter a phrase: I am a boy\n","Opposite Phrase: i am a girl\n","Enter a phrase: I am happy\n","Opposite Phrase: I am sad I am apprehensive\n","Enter a phrase: I am an only child\n","Opposite Phrase: I am a skeptic\n","Enter a phrase: I go to school \n","Opposite Phrase: a   Cess to\n","Enter a phrase: I am not a student\n","Opposite Phrase: a student. I am not a student.\n","Enter a phrase: I hate cows.\n","Opposite Phrase: I love cows\n","Enter a phrase: I love eating pancakes\n","Opposite Phrase: I hate pancakes\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-50d051af88ea>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Type 'quit' to exit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minput_phrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter a phrase: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_phrase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}],"source":["print(\"Type 'quit' to exit.\")\n","while True:\n","    input_phrase = input(\"Enter a phrase: \")\n","    if input_phrase.lower() == 'quit':\n","        break\n","\n","    # Get the opposite phrase\n","    opposite_phrase = get_opposite_phrase(opposite_maker, tokenizer, input_phrase)\n","    print(\"Opposite Phrase:\", opposite_phrase)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyM2SQjFvY7JF3MXhi5EdKHk"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9becf1e6c8264c28ae11eabd9b8dc4f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d46cdeee93345fb8f5f97679141a35a","IPY_MODEL_da00efb1606d43dea5eabd7ea8839d5e","IPY_MODEL_4721ea7b592d4f30ba45c109c6ec72db"],"layout":"IPY_MODEL_f32edc2f0e204cb7a524cc6e948450c1"}},"7d46cdeee93345fb8f5f97679141a35a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81e725133ac14f319e292204aa366655","placeholder":"","style":"IPY_MODEL_2e9b39eaf5174e19a764e623e411c674","value":"tokenizer_config.json:100%"}},"da00efb1606d43dea5eabd7ea8839d5e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61e8a7b3eff6407f94588532764b215e","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af13c2e5e3f04b29853ad5f3f54f61dc","value":48}},"4721ea7b592d4f30ba45c109c6ec72db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e81988548d5d44fe83cea97897c82efd","placeholder":"","style":"IPY_MODEL_5a31c775670a4cc5b9dc983786cd2358","value":"48.0/48.0[00:00&lt;00:00,1.16kB/s]"}},"f32edc2f0e204cb7a524cc6e948450c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81e725133ac14f319e292204aa366655":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e9b39eaf5174e19a764e623e411c674":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61e8a7b3eff6407f94588532764b215e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af13c2e5e3f04b29853ad5f3f54f61dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e81988548d5d44fe83cea97897c82efd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a31c775670a4cc5b9dc983786cd2358":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"adeab4faffb94c6ab5d346b832f8fd12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46287272713b4d75963ec71b2630082e","IPY_MODEL_bcd296de8e3447798e4906c30a9e71ac","IPY_MODEL_c39c8744f17443b38932971d703bac6b"],"layout":"IPY_MODEL_fb139b4d17494308b7d4a5e8eb8da8bc"}},"46287272713b4d75963ec71b2630082e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac496162743e4e71b2ee10102e27d8ad","placeholder":"","style":"IPY_MODEL_f0d6e1507523449abcf58fb3942cb531","value":"vocab.txt:100%"}},"bcd296de8e3447798e4906c30a9e71ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75fb418e36a2470e914c2369fad83a43","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04b60d8758594525a3c71934ab18c134","value":231508}},"c39c8744f17443b38932971d703bac6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd1f1b105fcb4bd1b356a03ca2c15b37","placeholder":"","style":"IPY_MODEL_b5ae41ed0bcc4d4db7766b0bf058c88f","value":"232k/232k[00:00&lt;00:00,4.62MB/s]"}},"fb139b4d17494308b7d4a5e8eb8da8bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac496162743e4e71b2ee10102e27d8ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0d6e1507523449abcf58fb3942cb531":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75fb418e36a2470e914c2369fad83a43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04b60d8758594525a3c71934ab18c134":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd1f1b105fcb4bd1b356a03ca2c15b37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5ae41ed0bcc4d4db7766b0bf058c88f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f852cdaabacc4ea18a26af8b97d51e0e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04ae7e524e4849aab34e605c4d08be69","IPY_MODEL_035605a502b540da9673caba009d2ec4","IPY_MODEL_8bff3240474c4070bcc4ed5548d508d7"],"layout":"IPY_MODEL_68b0b40a01cc4641838ff3047f4d53ce"}},"04ae7e524e4849aab34e605c4d08be69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_317a62c226c04702b4011ed54311b070","placeholder":"","style":"IPY_MODEL_5e58c6ecd35545698cbeea1737927911","value":"tokenizer.json:100%"}},"035605a502b540da9673caba009d2ec4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79159947af4c4c1c8ffeb643f0acff32","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b835a2df8804fe8969a4bf0842bf80c","value":466062}},"8bff3240474c4070bcc4ed5548d508d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b32757851d4c47b198f899aa13d9216f","placeholder":"","style":"IPY_MODEL_455108439a204b5ca066f14c005b96eb","value":"466k/466k[00:00&lt;00:00,1.96MB/s]"}},"68b0b40a01cc4641838ff3047f4d53ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"317a62c226c04702b4011ed54311b070":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e58c6ecd35545698cbeea1737927911":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79159947af4c4c1c8ffeb643f0acff32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b835a2df8804fe8969a4bf0842bf80c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b32757851d4c47b198f899aa13d9216f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"455108439a204b5ca066f14c005b96eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59b0fbda46b945179063319e2f375822":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_96b61acd934d4a578459f03ebed3e82e","IPY_MODEL_2b45274f82df42f9be45789990ba0136","IPY_MODEL_064eccaff77b470c8eddd96ab8ab97a8"],"layout":"IPY_MODEL_f66e86bceec74a339f9e6607d4c8b5ea"}},"96b61acd934d4a578459f03ebed3e82e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73a9af4a40cf413a8490d3007355d73c","placeholder":"","style":"IPY_MODEL_5e282157683948279b4bfe3bfc181808","value":"config.json:100%"}},"2b45274f82df42f9be45789990ba0136":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15f1e402040b40389f3208472a016b64","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c99944b4247c44ba98606efc4db7d18a","value":570}},"064eccaff77b470c8eddd96ab8ab97a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_362d8dab81174555972a5bf0abc7d598","placeholder":"","style":"IPY_MODEL_dd10a53c5f444e82a453f2548451d9aa","value":"570/570[00:00&lt;00:00,7.31kB/s]"}},"f66e86bceec74a339f9e6607d4c8b5ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73a9af4a40cf413a8490d3007355d73c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e282157683948279b4bfe3bfc181808":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15f1e402040b40389f3208472a016b64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c99944b4247c44ba98606efc4db7d18a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"362d8dab81174555972a5bf0abc7d598":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd10a53c5f444e82a453f2548451d9aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24c8c7bb479c476897575bd72777ca47":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71852ac9983e4bb981d5fe40874a8cc4","IPY_MODEL_30501c4cb07440a0a52259f5b68e2a0b","IPY_MODEL_c259dd5e400440139febb558df72c602"],"layout":"IPY_MODEL_0a4fecc0f41948c99e4849db0e1334dd"}},"71852ac9983e4bb981d5fe40874a8cc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a037cd3d0a454c6693ab8db9fe1dcb0a","placeholder":"","style":"IPY_MODEL_61919d4af93d418c8e95db48c2e21505","value":"model.safetensors:100%"}},"30501c4cb07440a0a52259f5b68e2a0b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_06dca4d3741e46b29301017e191bcac8","max":891646390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87a5ac69d1194da79f4fa582dce365f3","value":891646390}},"c259dd5e400440139febb558df72c602":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72a3f8ee9fff4bc58bffa2376391b807","placeholder":"","style":"IPY_MODEL_eb6212046803435babddb59dccbdd703","value":"892M/892M[00:07&lt;00:00,287MB/s]"}},"0a4fecc0f41948c99e4849db0e1334dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a037cd3d0a454c6693ab8db9fe1dcb0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61919d4af93d418c8e95db48c2e21505":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06dca4d3741e46b29301017e191bcac8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87a5ac69d1194da79f4fa582dce365f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72a3f8ee9fff4bc58bffa2376391b807":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb6212046803435babddb59dccbdd703":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65f94b0fb5f7478eafb10ba14a3d8197":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ddaf77ab376a424caedbb71b1eb8b797","IPY_MODEL_0ebd844fe27c43a8b9818e0066c558e4","IPY_MODEL_d3c53b73b2a8400c84b4dca2423a4c76"],"layout":"IPY_MODEL_f8effce9164741f3be6ed9b99ffe12ed"}},"ddaf77ab376a424caedbb71b1eb8b797":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10d52cbb9ef243b8a9ec64e3da6a9924","placeholder":"","style":"IPY_MODEL_4683043c2bd84186a57b237eb3bc4b4a","value":"generation_config.json:100%"}},"0ebd844fe27c43a8b9818e0066c558e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc58abb372e24577800de18c25e43047","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40d75efe6d864308b65c470d7e6e0b0e","value":147}},"d3c53b73b2a8400c84b4dca2423a4c76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e66fd31cbe34fdcb39133998f3c9ec8","placeholder":"","style":"IPY_MODEL_6d4ac403500c4332a9e8d6b941680413","value":"147/147[00:00&lt;00:00,8.91kB/s]"}},"f8effce9164741f3be6ed9b99ffe12ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10d52cbb9ef243b8a9ec64e3da6a9924":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4683043c2bd84186a57b237eb3bc4b4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc58abb372e24577800de18c25e43047":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40d75efe6d864308b65c470d7e6e0b0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e66fd31cbe34fdcb39133998f3c9ec8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d4ac403500c4332a9e8d6b941680413":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}